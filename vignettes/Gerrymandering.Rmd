---
title: "Gerrymandering Vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Gerrymandering Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This is a package designed to calculate the efficiency gap, a metric of partisan gerrymandering, for the Wisconsin General Assembly, from 2006 to 2020. 

Every ten years, the United States of America performs a census of its citizens. Following the census, each state undergoes the process of redistricting to account for demographic movement, in which they redraw their congressional and state legislative maps to ensure population equality amongst the districts. However, the boundaries are typically drawn by partisan actors, who use this process to exclude specific groups from representation and entrench their own ideals. This process is called gerrymandering, and in this package, we will examine partisan gerrymandering, which is when districts are drawn to dilute the voting power of a party. 

Partisan gerrymandering can occur anytime any maps are drawn for the single-member district, first-past-the-post electoral system in use in the United States. Whereas most research on partisan gerrymandering focuses on quantifying the distortions federally within the House of Representatives, we are interested in quantifying partisan gerrymandering as it occurs within state legislatures. More specifically, we are observing Wisconsin's General Assembly, the statewide equivalent of the House of Representatives, with data gathered from 2006 to 2020. Wisconsin has been a hotbed of gerrymandering since the 2012 redistricting, and its maps have been the focus of several court cases, both before state and federal courts. We are assessing State Assembly seats instead of State Senate seats because there are more Assembly districts than Senate, which gives more concentrated opportunities for analysis, as well as the fact that Assembly members are elected every two years, while Senators are staggered. This gives us far more data points, and mirrors research conducted on Congress. Notably, the Wisconsin General Assembly maps were found by the State Supreme Court in [*Gill v. Whitford*](https://www.supremecourt.gov/opinions/17pdf/16-1161_dc8f.pdf) (2018) to be unconstitutional partisan gerrymanders, and the efficiency gap was used to make the argument. Since the 2020 round of redistricting has occurred, the current maps have been in the midst of intense litigation, so it is helpful to truly understand how to quantify the metric and how the past decade has shaped the state's redistricting trajectory. 

To measure partisan gerrymandering, we are using the [efficiency gap](https://chicagounbound.uchicago.edu/cgi/viewcontent.cgi?article=1946&context=public_law_and_legal_theory). Devised in 2014 by political scientists Nicholas Stephanopoulos and Eric McGhee, the efficiency gap aims to quantify the seats to votes distortion. It recognizes that complete proportionality is not only impossible given the geographic distribution of partisans, but is not a constitutional right, as affirmed by Chief Justice Roberts in [*Rucho v. Common Cause*] (https://www.supremecourt.gov/opinions/18pdf/18-422_9ol1.pdf). The efficiency gap allows a winner's bonus, or a slight extra boost in seat share to the majority party. The winner's bonus is violated however, and a gerrymander is considered to be egregious when the gap itself exceeds +/- 0.08, where negative numbers indicate the presence of a pro-Republican gerrymander, and positive numbers for pro-Democratic maps. 

This package is fundamental to the honors thesis of Molly Zelloe, and the functions here are performing the invaluable calculations that she needs to address a gap in the literature. 

```{r setup}
library(gerrymandering)
library(tidyverse)
```

## Datasets

The package calls on data from the OpenElections Github repositories. [OpenElections](https://github.com/openelections) is a volunteer organization that organizes, cleans, and produces election data for every year, for every state, stretching back through 2000. Because this is a volunteer organization, not every state's data is equally clean, or even available, as was the case with Wisconsin's 2004 district-based data. We dealt with this issue by building the functions to only calculate information for years 2006 through 2020, as we can still use the statewide races provided in the 2004 data to calculate baselines. 

## Who Should Use This Package?

Political science researchers, or anyone interested in the processes of redistricting can use the package to explore Wisconsin's redistricting environment, or take inspiration from the functions presented here to pursue analysis of states of their choosing. 

## What Can We Do With This Data?

There are four objects that are returned from the functionality of the data, and each can have different uses.

# Example 1: Full state data

The user must first call the `open_elections_factory` on a state. As of right now, the only state that will be accepted is Wisconsin, inputted as its abbreviation, "wi", as a character vector. This returns a function, not an object. 

From there, the user can call `generate_data` on the function defined in the above factory, which is necessary to load the Wisconsin data from OpenElections for 2000 through 2020. The first object that our functions generate is a list of data frames, where each list element exists for a year's worth of electoral data. Each year can be indexed to yield data frames. This data frame can be manipulated to the user's whims such as but not limited to exploring ward behavior, the presence of third parties, or differences in votes cast among office. 

Running `access_state_year` with the year as a character vector as the first argument and the data set as the second argument will generate a data frame for just the year the user would like to observe. 

To view only the contested districts for the data set, one can run `sa_contest_all`, which will return a list of data frames where each element corresponds with a given year. The user can then examine the amount of contested districts in each year, and use this for future analysis on competitiveness. 

```{r}
oe_data <- open_elections_factory("wi")

data <- generate_data(oe_data)

data[[6]]

data_2010 <- access_state_year("2010", data)

contested <- sa_contest_all(data)
```

# Example 2: Baselines

The second object that is generated with our functions is the state assembly district baseline, which is calculated for each district that is uncontested in a given year. We used the notion of a baseline, as designed for U.S. House districts by [*Inside Elections*](https://www.insideelections.com/news/article/methodology-inside-elections-baseline-by-congressional-district). When given an uncontested district for a year, the function will pull statewide data associated with that legislative district's wards, isolating how that group of people voted for all offices (President, Senate, etc.) in that cycle. The function then pulls the voter data for that legislative district in the two election cycles prior, including previous state assembly results assuming the district was previously contested. From there, we create a trimmed means, where we remove the race with the highest Democratic vote share, and the race with the highest Republican vote share. The columns are then collapsed and averaged into the baseline: the average two party vote, and average Republican and Democrat vote shares. The baseline tells us how a district would have behaved, if it had been contested in that year. 

The information here can be further examined if one was curious in the ratio of contested and uncontested districts, how much we estimated vote shares for them in comparison to other districts and years, and so forth. 

It is normal for this step to generate a series of messages regarding the summarize function. These are no reason for concern. 

```{r}
votes_2010 <- year_baseline_data(2010, data)

votes_2016 <- year_baseline_data(2016, data)
```

## Example 3: Calculating Efficiency Gaps

The final two objects that we can calculate for in this package are the efficiency gaps. The primary efficiency gap function, `efficiency_gap`, pulls on our preset data frame for each year's legislative compositions to calculate the seats-votes relationship. This function uses all of the estimated baselines and covers all districts for a given year. These values can be further studied and averaged over the whole redistricting cycle. 

The second form of the efficiency gap that we calculated, `efficiency_gap_contested`, has the same formula as the other, but only includes contested districts. Removing our baseline estimates show the troubling effects that these uncontested districts have on measurements: if unaccounted for, the results change drastically. We wanted to include both versions to highlight the importance of our generated, baseline data. 

```{r}
eg_2010 <- efficiency_gap(votes_2010, 2010)

eg_2016 <- efficiency_gap(votes_2016, 2016)

eg_con_2010 <- efficiency_gap_contested(votes_2010, 2010)

eg_con_2016 <- efficiency_gap_contested(votes_2016, 2016)
```

The results of the efficiency gaps here can be interpreted. The gap for 2010 of -0.067 presents an indication of a likely Republican gerrymander, but it is below the +/- 0.08 threshold set forth by Stephanopoulos and McGhee to make it unconstitutional. The same results for only contested districts shows nearly neutral maps, with the value being -0.01. If one was only using the contested districts, they would interpret the results as being neutral, which we know they are not. For 2016, however, the differences grow more disparate. The regular gap in 2016 was -0.096, which is beyond the benchmark of the authors, indicating the maps as particularly egregious. However, when the contested form is taken, it presents a slight Democratic gerrymander at 0.036. Again, this shows the sensitivity of the metric, but the importance of considering uncontested districts, especially when observing behavior of an entire state and state assembly. 
